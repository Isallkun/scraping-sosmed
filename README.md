# Social Media Scraper Automation

An automated system for scraping social media data, performing sentiment analysis, and generating reports using n8n workflow orchestration.

## Features

- ğŸ” **Web Scraping**: Automated data collection from Instagram, Twitter, and Facebook using Selenium
- ğŸ­ **Anti-Detection**: Random user agents, viewport sizes, and human-like delays to avoid bot detection
- ğŸ“Š **Sentiment Analysis**: Analyze text sentiment using VADER and TextBlob models
- ğŸ—„ï¸ **Data Storage**: PostgreSQL database for structured data storage with automatic backups
- ğŸ”„ **Workflow Automation**: n8n workflows for scheduled scraping, on-demand analysis, and weekly reporting
- ğŸ“§ **Notifications**: Email, Slack, and Telegram alerts for workflow status and errors
- ğŸ³ **Docker Deployment**: Containerized deployment for easy setup and scalability

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        n8n Workflows                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Daily Cron   â”‚  â”‚  On-Demand   â”‚  â”‚   Weekly     â”‚      â”‚
â”‚  â”‚   Workflow   â”‚  â”‚   Webhook    â”‚  â”‚   Report     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Python Services Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Selenium Scraper    â”‚â”€â”€â”€â–¶â”‚  Sentiment Analyzer  â”‚      â”‚
â”‚  â”‚  - Login automation  â”‚    â”‚  - Text cleaning     â”‚      â”‚
â”‚  â”‚  - Data extraction   â”‚    â”‚  - VADER/TextBlob    â”‚      â”‚
â”‚  â”‚  - Anti-detection    â”‚    â”‚  - Batch processing  â”‚      â”‚
â”‚  â”‚  - Rate limiting     â”‚    â”‚  - Score calculation â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                          â”‚
              â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL Database                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  posts   â”‚  â”‚sentimentsâ”‚  â”‚ execution_logs   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
.
â”œâ”€â”€ scraper/                    # Web scraping module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_scraper.py        # CLI entry point
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ scrapers/              # Platform-specific scrapers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py   # Abstract base class
â”‚   â”‚   â”œâ”€â”€ instagram.py      # Instagram scraper
â”‚   â”‚   â”œâ”€â”€ twitter.py        # Twitter scraper
â”‚   â”‚   â””â”€â”€ facebook.py       # Facebook scraper
â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ anti_detection.py # Anti-detection measures
â”‚       â”œâ”€â”€ rate_limiter.py   # Rate limiting
â”‚       â””â”€â”€ logger.py         # Logging configuration
â”‚
â”œâ”€â”€ sentiment/                  # Sentiment analysis module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment_analyzer.py # Main analyzer
â”‚   â”œâ”€â”€ text_cleaner.py       # Text preprocessing
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â””â”€â”€ models/               # Sentiment models
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ vader_model.py    # VADER implementation
â”‚       â””â”€â”€ textblob_model.py # TextBlob implementation
â”‚
â”œâ”€â”€ database/                   # Database module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_connection.py      # Connection pooling
â”‚   â”œâ”€â”€ db_operations.py      # CRUD operations
â”‚   â”œâ”€â”€ migrations/           # SQL migration scripts
â”‚   â””â”€â”€ scripts/              # Backup and maintenance scripts
â”‚
â”œâ”€â”€ n8n/                       # n8n workflow configurations
â”‚   â”œâ”€â”€ workflows/            # Workflow JSON exports
â”‚   â””â”€â”€ .env.n8n.example     # n8n environment variables
â”‚
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ setup.sh             # Docker setup script
â”‚   â”œâ”€â”€ health_check.py      # Health monitoring
â”‚   â””â”€â”€ notify.py            # Notification utilities
â”‚
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/                # Unit tests
â”‚   â”œâ”€â”€ property/            # Property-based tests
â”‚   â””â”€â”€ integration/         # Integration tests
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”œâ”€â”€ docker-compose.yml        # Docker Compose configuration
â”œâ”€â”€ Dockerfile               # Python service Dockerfile
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # This file
```

## ğŸš€ Quick Start

### âš¡ Fastest Way (3 Commands)

```bash
# 1. Generate demo data (no login required)
python demo_scraper.py

# 2. Analyze sentiment
python -m sentiment.main_analyzer --input output/demo_instagram_posts_TIMESTAMP.json --output output/demo_instagram_posts_TIMESTAMP_sentiment.json

# 3. View beautiful results
python view_results.py output/demo_instagram_posts_TIMESTAMP_sentiment.json
```

**See [QUICK_REFERENCE.md](QUICK_REFERENCE.md) for more commands!**

---

### Prerequisites

- Python 3.11+
- Chrome/Chromium browser (for real scraping)
- Instagram account (for real scraping)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd social-media-scraper-automation
   ```

2. **Set up Python virtual environment**
   ```bash
   # Windows
   setup_venv.bat
   
   # Linux/Mac
   chmod +x setup_venv.sh
   ./setup_venv.sh
   ```

3. **Configure credentials (for real scraping)**
   ```bash
   # Edit .env file with your Instagram credentials
   INSTAGRAM_USERNAME=your_username
   INSTAGRAM_PASSWORD=your_password
   ```

### Usage

#### ğŸ“¸ Real Instagram Scraping (Simplified & Fast)

```bash
# Scrape 5 posts from a profile (includes both posts and reels)
python scrape_instagram_simple.py https://www.instagram.com/rusdi_sutejo/ 5

# Analyze sentiment
python -m sentiment.main_analyzer --input output/instagram_simple_TIMESTAMP.json --output output/instagram_simple_TIMESTAMP_sentiment.json

# View results
python view_results.py output/instagram_simple_TIMESTAMP_sentiment.json
```

**Status**: âœ… **WORKING** - Tested February 9, 2026  
**Features**:
- âœ… Scrapes both regular posts (`/p/`) and reels (`/reel/`)
- âœ… Enhanced comment extraction with 3-strategy fallback
- âœ… Extracts comment text, author, and timestamp
- âœ… Supports Indonesian and English UI

**See**: [docs/INSTAGRAM_SIMPLIFIED_GUIDE.md](docs/INSTAGRAM_SIMPLIFIED_GUIDE.md) for complete guide

#### ğŸ­ Demo Mode (Safe Testing)

```bash
# Generate demo data
python demo_scraper.py

# Analyze demo data
python -m sentiment.main_analyzer --input output/demo_instagram_posts_TIMESTAMP.json --output output/demo_instagram_posts_TIMESTAMP_sentiment.json

# View demo results
python view_results.py output/demo_instagram_posts_TIMESTAMP_sentiment.json
```

**Status**: âœ… **100% WORKING** - No credentials needed

#### ğŸ”„ Batch Scripts (Windows)

```bash
# Quick scraping
run_scraper.bat

# Quick sentiment analysis
run_sentiment.bat output/instagram_simple_TIMESTAMP.json
```

## Configuration

All configuration is managed through environment variables. See `.env.example` for a complete list of available options.

### Key Configuration Options

- `SCRAPER_PLATFORM`: Target platform (instagram, twitter, facebook)
- `SCRAPER_RATE_LIMIT`: Requests per minute (default: 30)
- `SENTIMENT_MODEL`: Sentiment model (vader, textblob)
- `DATABASE_URL`: PostgreSQL connection string
- `SMTP_*`: Email notification settings
- `SLACK_WEBHOOK_URL`: Slack notification webhook

## ğŸ“‹ Output Schema

### Enhanced Instagram Post Object

The scraper now extracts both posts and reels with enhanced comment data:

```json
{
  "post_id": "ABC123xyz",
  "post_type": "post",
  "post_url": "https://www.instagram.com/username/p/ABC123xyz/",
  "author": "username",
  "content": "Post caption text here...",
  "timestamp": "2026-02-09T09:38:10.803159Z",
  "likes": 146,
  "comments_count": 5,
  "comments": [
    {
      "author": "commenter1",
      "text": "Great post!",
      "timestamp": "2026-02-09T10:00:00Z"
    },
    {
      "author": "commenter2",
      "text": "Love this content!",
      "timestamp": "2026-02-09T10:15:00Z"
    }
  ],
  "hashtags": ["#example", "#instagram"],
  "scraped_at": "2026-02-09T09:38:10.803159Z"
}
```

### New Fields

- **`post_type`**: Identifies content as `"post"` or `"reel"` based on URL pattern
- **`comments`**: Array of comment objects with:
  - `author`: Username of commenter
  - `text`: Comment text content
  - `timestamp`: ISO 8601 timestamp (when available)

### Enhanced Metadata

```json
{
  "platform": "instagram",
  "scraped_at": "2026-02-09T02:38:33.302169Z",
  "target_url": "https://www.instagram.com/username/",
  "total_posts": 10,
  "post_count": 6,
  "reel_count": 4,
  "total_comments": 25,
  "scrape_comments": true,
  "comments_per_post": 20,
  "method": "enhanced with comments"
}
```

### Comment Extraction Strategies

The scraper uses a 3-strategy fallback approach for robust comment extraction:

1. **Strategy 1: Page Source JSON** - Parses embedded JSON from `window._sharedData` or `__additionalDataLoaded`
2. **Strategy 2: DOM Extraction** - Uses WebDriverWait and DOM selectors to extract comments with:
   - Automatic "View all comments" button clicking
   - Scroll and "Load more" support (up to 5 iterations)
   - Filters out captions and UI text
3. **Strategy 3: JavaScript Fallback** - Direct DOM query via `execute_script()` for elements Selenium might miss

Each strategy is tried in order until comments are successfully extracted. If all strategies fail, an empty array is returned (graceful degradation).

## Security & Compliance

âš ï¸ **Important Disclaimers**:

- This tool is for educational and research purposes
- Always respect platform Terms of Service and robots.txt
- Use rate limiting to avoid overwhelming servers
- Never share or expose credentials
- Comply with data privacy regulations (GDPR, CCPA, etc.)

### Security Best Practices

- Store credentials in environment variables, never in code
- Use rate limiting to respect platform limits
- Run containers as non-root users
- Regularly update dependencies for security patches
- Enable log sanitization to prevent credential leaks

## âœ… Current Status

### Working Features
- âœ… **Demo Mode** - 100% working, generates sample data
- âœ… **Instagram Scraping** - Simplified fast scraper working (tested Feb 9, 2026)
- âœ… **Sentiment Analysis** - VADER and TextBlob models working
- âœ… **Results Viewer** - Beautiful formatted output
- âœ… **Database Integration** - PostgreSQL storage working
- âœ… **Testing Suite** - 305 tests passing (100% pass rate)

### In Development
- ğŸ”„ Twitter scraping (basic implementation done)
- ğŸ”„ Facebook scraping (basic implementation done)
- ğŸ”„ n8n workflow automation
- ğŸ”„ Full Instagram data extraction (UI changes make this challenging)

### Known Limitations
- âš ï¸ Instagram simplified scraper extracts minimal data (post IDs and URLs)
- âš ï¸ Full caption/likes/comments extraction affected by Instagram UI changes
- âš ï¸ Twitter and Facebook scrapers need real-world testing

**See [docs/REAL_SCRAPING_COMPLETION.md](docs/REAL_SCRAPING_COMPLETION.md) for detailed status**

---

## Testing

```bash
# Run all tests (305 tests)
pytest

# Run specific test file
pytest tests/test_instagram_scraper.py

# Run with verbose output
pytest -v

# Run with coverage
pytest --cov=scraper --cov=sentiment
```

**Test Status**: âœ… 305 tests passing, 0 failures

---

## ğŸ“š Documentation

### Quick Guides
- **[QUICK_REFERENCE.md](QUICK_REFERENCE.md)** - âš¡ Quick command reference
- **[docs/QUICKSTART.md](docs/QUICKSTART.md)** - ğŸš€ Quick start guide
- **[docs/USAGE_GUIDE.md](docs/USAGE_GUIDE.md)** - ğŸ“– Complete usage guide

### Instagram Scraping
- **[docs/INSTAGRAM_SIMPLIFIED_GUIDE.md](docs/INSTAGRAM_SIMPLIFIED_GUIDE.md)** - ğŸ“¸ Simplified scraping guide
- **[docs/REAL_SCRAPING_GUIDE.md](docs/REAL_SCRAPING_GUIDE.md)** - âš ï¸ Real scraping warnings
- **[docs/REAL_SCRAPING_COMPLETION.md](docs/REAL_SCRAPING_COMPLETION.md)** - âœ… Completion summary

### Troubleshooting
- **[docs/TROUBLESHOOTING.md](docs/TROUBLESHOOTING.md)** - ğŸ”§ Common issues and solutions

### Database & Setup
- **[database/README.md](database/README.md)** - ğŸ—„ï¸ Database setup guide
- **[docs/SETUP.md](docs/SETUP.md)** - âš™ï¸ Detailed setup instructions

## Troubleshooting

### Common Issues

**Selenium WebDriver errors**:
- Ensure Chrome/Chromium is installed
- Check ChromeDriver version matches Chrome version
- Try running in non-headless mode for debugging

**Database connection errors**:
- Verify PostgreSQL is running
- Check DATABASE_URL in .env
- Ensure database exists and user has permissions

**Rate limiting / IP blocking**:
- Increase delay between requests
- Use residential proxies
- Reduce SCRAPER_RATE_LIMIT value

## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- [Selenium](https://www.selenium.dev/) - Web browser automation
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment) - Social media sentiment analysis
- [n8n](https://n8n.io/) - Workflow automation platform
- [PostgreSQL](https://www.postgresql.org/) - Database system

## Support

For issues, questions, or contributions, please open an issue on GitHub.

---

**Disclaimer**: This tool is provided as-is for educational purposes. Users are responsible for ensuring their use complies with applicable laws, regulations, and platform terms of service.

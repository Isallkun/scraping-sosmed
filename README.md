# Social Media Scraper Automation

An automated system for scraping social media data, performing sentiment analysis, and generating reports using n8n workflow orchestration.

## Features

- ğŸ” **Web Scraping**: Automated data collection from Instagram, Twitter, and Facebook using Selenium
- ğŸ­ **Anti-Detection**: Random user agents, viewport sizes, and human-like delays to avoid bot detection
- ğŸ“Š **Sentiment Analysis**: Analyze text sentiment using VADER and TextBlob models
- ğŸ—„ï¸ **Data Storage**: PostgreSQL database for structured data storage with automatic backups
- ğŸ”„ **Workflow Automation**: n8n workflows for scheduled scraping, on-demand analysis, and weekly reporting
- ğŸ“§ **Notifications**: Email, Slack, and Telegram alerts for workflow status and errors
- ğŸ³ **Docker Deployment**: Containerized deployment for easy setup and scalability

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        n8n Workflows                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚ Daily Cron   â”‚  â”‚  On-Demand   â”‚  â”‚   Weekly     â”‚      â”‚
â”‚  â”‚   Workflow   â”‚  â”‚   Webhook    â”‚  â”‚   Report     â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                  â”‚                  â”‚
          â–¼                  â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Python Services Layer                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  Selenium Scraper    â”‚â”€â”€â”€â–¶â”‚  Sentiment Analyzer  â”‚      â”‚
â”‚  â”‚  - Login automation  â”‚    â”‚  - Text cleaning     â”‚      â”‚
â”‚  â”‚  - Data extraction   â”‚    â”‚  - VADER/TextBlob    â”‚      â”‚
â”‚  â”‚  - Anti-detection    â”‚    â”‚  - Batch processing  â”‚      â”‚
â”‚  â”‚  - Rate limiting     â”‚    â”‚  - Score calculation â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                          â”‚
              â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PostgreSQL Database                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  posts   â”‚  â”‚sentimentsâ”‚  â”‚ execution_logs   â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Project Structure

```
.
â”œâ”€â”€ scraper/                    # Web scraping module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main_scraper.py        # CLI entry point
â”‚   â”œâ”€â”€ config.py              # Configuration management
â”‚   â”œâ”€â”€ scrapers/              # Platform-specific scrapers
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_scraper.py   # Abstract base class
â”‚   â”‚   â”œâ”€â”€ instagram.py      # Instagram scraper
â”‚   â”‚   â”œâ”€â”€ twitter.py        # Twitter scraper
â”‚   â”‚   â””â”€â”€ facebook.py       # Facebook scraper
â”‚   â””â”€â”€ utils/                 # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ anti_detection.py # Anti-detection measures
â”‚       â”œâ”€â”€ rate_limiter.py   # Rate limiting
â”‚       â””â”€â”€ logger.py         # Logging configuration
â”‚
â”œâ”€â”€ sentiment/                  # Sentiment analysis module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ sentiment_analyzer.py # Main analyzer
â”‚   â”œâ”€â”€ text_cleaner.py       # Text preprocessing
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â””â”€â”€ models/               # Sentiment models
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ vader_model.py    # VADER implementation
â”‚       â””â”€â”€ textblob_model.py # TextBlob implementation
â”‚
â”œâ”€â”€ database/                   # Database module
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ db_connection.py      # Connection pooling
â”‚   â”œâ”€â”€ db_operations.py      # CRUD operations
â”‚   â”œâ”€â”€ migrations/           # SQL migration scripts
â”‚   â””â”€â”€ scripts/              # Backup and maintenance scripts
â”‚
â”œâ”€â”€ n8n/                       # n8n workflow configurations
â”‚   â”œâ”€â”€ workflows/            # Workflow JSON exports
â”‚   â””â”€â”€ .env.n8n.example     # n8n environment variables
â”‚
â”œâ”€â”€ scripts/                   # Utility scripts
â”‚   â”œâ”€â”€ setup.sh             # Docker setup script
â”‚   â”œâ”€â”€ health_check.py      # Health monitoring
â”‚   â””â”€â”€ notify.py            # Notification utilities
â”‚
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ unit/                # Unit tests
â”‚   â”œâ”€â”€ property/            # Property-based tests
â”‚   â””â”€â”€ integration/         # Integration tests
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”œâ”€â”€ docker-compose.yml        # Docker Compose configuration
â”œâ”€â”€ Dockerfile               # Python service Dockerfile
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # This file
```

## Quick Start

### Prerequisites

- Python 3.11+
- Docker and Docker Compose
- PostgreSQL 14+ (or use Docker)
- Chrome/Chromium browser (for Selenium)

### Installation

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd social-media-scraper-automation
   ```

2. **Set up Python virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   pip install -r requirements.txt
   ```

3. **Configure environment variables**
   ```bash
   cp .env.example .env
   # Edit .env with your credentials and configuration
   ```

4. **Run with Docker (Recommended)**
   ```bash
   docker-compose up -d
   ```

   Or use the setup script:
   ```bash
   chmod +x scripts/setup.sh
   ./scripts/setup.sh
   ```

### Usage

#### CLI Scraping

```bash
# Scrape Instagram posts
python scraper/main_scraper.py \
  --platform instagram \
  --target "https://instagram.com/username" \
  --limit 50 \
  --output posts.json

# Analyze sentiment
python sentiment/sentiment_analyzer.py \
  --input posts.json \
  --output posts_with_sentiment.json \
  --model vader
```

#### n8n Workflows

Access n8n at `http://localhost:5678` and import workflows from `n8n/workflows/`:

- **Daily Scraping**: Automated daily data collection (runs at 2 AM)
- **On-Demand Webhook**: Trigger scraping via HTTP POST to `/webhook/scrape`
- **Weekly Report**: Generate and email weekly insights (runs Sunday 9 AM)

## Configuration

All configuration is managed through environment variables. See `.env.example` for a complete list of available options.

### Key Configuration Options

- `SCRAPER_PLATFORM`: Target platform (instagram, twitter, facebook)
- `SCRAPER_RATE_LIMIT`: Requests per minute (default: 30)
- `SENTIMENT_MODEL`: Sentiment model (vader, textblob)
- `DATABASE_URL`: PostgreSQL connection string
- `SMTP_*`: Email notification settings
- `SLACK_WEBHOOK_URL`: Slack notification webhook

## Security & Compliance

âš ï¸ **Important Disclaimers**:

- This tool is for educational and research purposes
- Always respect platform Terms of Service and robots.txt
- Use rate limiting to avoid overwhelming servers
- Never share or expose credentials
- Comply with data privacy regulations (GDPR, CCPA, etc.)

### Security Best Practices

- Store credentials in environment variables, never in code
- Use rate limiting to respect platform limits
- Run containers as non-root users
- Regularly update dependencies for security patches
- Enable log sanitization to prevent credential leaks

## Testing

```bash
# Run unit tests
pytest tests/unit/

# Run property-based tests
pytest tests/property/

# Run integration tests
pytest tests/integration/

# Run all tests with coverage
pytest --cov=. --cov-report=html
```

## Documentation

- [Architecture Details](ARCHITECTURE.md) - System design and component interactions
- [API Documentation](API.md) - Webhook endpoints and request/response formats
- [Security Guide](SECURITY.md) - Security best practices and compliance
- [Deployment Guide](DEPLOYMENT.md) - Docker deployment instructions
- [Database Restore](database/RESTORE.md) - Backup and restore procedures

## Troubleshooting

### Common Issues

**Selenium WebDriver errors**:
- Ensure Chrome/Chromium is installed
- Check ChromeDriver version matches Chrome version
- Try running in non-headless mode for debugging

**Database connection errors**:
- Verify PostgreSQL is running
- Check DATABASE_URL in .env
- Ensure database exists and user has permissions

**Rate limiting / IP blocking**:
- Increase delay between requests
- Use residential proxies
- Reduce SCRAPER_RATE_LIMIT value

## Contributing

Contributions are welcome! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- [Selenium](https://www.selenium.dev/) - Web browser automation
- [VADER Sentiment](https://github.com/cjhutto/vaderSentiment) - Social media sentiment analysis
- [n8n](https://n8n.io/) - Workflow automation platform
- [PostgreSQL](https://www.postgresql.org/) - Database system

## Support

For issues, questions, or contributions, please open an issue on GitHub.

---

**Disclaimer**: This tool is provided as-is for educational purposes. Users are responsible for ensuring their use complies with applicable laws, regulations, and platform terms of service.
